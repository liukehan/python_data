{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Sigmoid Function and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def loss(output, Y):\n",
    "    return (-Y*np.log(output)-(1-Y)*np.log(1-output)).mean()\n",
    "\n",
    "def predict_train(data, theta, threshold):   \n",
    "    z = np.dot(data,theta)\n",
    "    output = sigmoid(z)\n",
    "    pred = (output > threshold).astype(float)\n",
    "    return pred\n",
    "\n",
    "def predict(data, theta, threshold): \n",
    "    test_data = np.array(data[[column for column in data.columns if column not in ['num', 'label']]])\n",
    "    labels = np.array(data['label'])\n",
    "    bias = np.ones((data.shape[0],1))\n",
    "    test_data = np.concatenate((test_data, bias), axis = 1)\n",
    "    z = np.dot(test_data,theta)\n",
    "    output = sigmoid(z)\n",
    "    pred = (output > threshold).astype(float)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(data, alpha, num_iters):#alpha is learning rate\n",
    "    \n",
    "    train_data = np.array(data[[column for column in data.columns if column not in ['num', 'label']]])\n",
    "    labels = np.array(data['label'])\n",
    "    bias = np.ones((data.shape[0],1))\n",
    "    train_data = np.concatenate((train_data, bias), axis = 1)\n",
    "    #theta's length is 1 + original column number\n",
    "    theta = np.ones(train_data.shape[1])\n",
    "    \n",
    "    for iteration in range(num_iters):\n",
    "        #don't do calculations in sigmoid function because\n",
    "        z = np.dot(train_data,theta)\n",
    "        output = sigmoid(z)\n",
    "        grad = -np.dot(train_data.T,(output - labels))/labels.size\n",
    "        theta += alpha * grad\n",
    "        if iteration%1000==0:\n",
    "            z = np.dot(train_data, theta)\n",
    "            output = sigmoid(z)\n",
    "            print (\"{} iterations, loss is {}\".format(iteration, loss(output, labels)))\n",
    "            print (\"Train accuracy is {}\".format((predict_train(train_data, theta, 0.5) == labels).mean())) \n",
    "            \n",
    "    result = {'theta':theta}\n",
    "    print('parameters:', theta)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations, loss is 0.9095877460739221\n",
      "Train accuracy is 0.5333333333333333\n",
      "1000 iterations, loss is 0.645078909348371\n",
      "Train accuracy is 0.6666666666666666\n",
      "2000 iterations, loss is 0.6336890071820886\n",
      "Train accuracy is 0.7333333333333333\n",
      "3000 iterations, loss is 0.6240511279507515\n",
      "Train accuracy is 0.7333333333333333\n",
      "4000 iterations, loss is 0.6154058983197058\n",
      "Train accuracy is 0.7333333333333333\n",
      "5000 iterations, loss is 0.6076303398220139\n",
      "Train accuracy is 0.7333333333333333\n",
      "6000 iterations, loss is 0.6006181910489847\n",
      "Train accuracy is 0.6666666666666666\n",
      "7000 iterations, loss is 0.5942771156356922\n",
      "Train accuracy is 0.6666666666666666\n",
      "8000 iterations, loss is 0.5885269838552352\n",
      "Train accuracy is 0.6666666666666666\n",
      "9000 iterations, loss is 0.5832982925255191\n",
      "Train accuracy is 0.6666666666666666\n",
      "parameters: [ 1.65874305  2.91677698 -1.30671982]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('watermelon.csv')\n",
    "model = logisticRegression(data.iloc[:15,:], alpha=0.01, num_iters = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is 0.5\n"
     ]
    }
   ],
   "source": [
    "test_data = data.iloc[15:,:]\n",
    "test_labels = data.iloc[15:,:]['label']\n",
    "print (\"The test accuracy is {}\".format((predict(test_data, model['theta'], 0.5) == test_labels).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
