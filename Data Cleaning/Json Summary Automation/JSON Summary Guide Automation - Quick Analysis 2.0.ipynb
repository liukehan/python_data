{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Read & Write JSON Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(data):\n",
    "    with open(folder + 'Summary_Guide.json', 'w') as json_file:\n",
    "        json_file.write(json.dumps(data))\n",
    "\n",
    "def load():\n",
    "    with open(folder + 'Summary_Guide.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_type(data, column): \n",
    "    if type(data[column][0]) == 'str':\n",
    "        return 'String'\n",
    "    else:\n",
    "        return 'Numeric'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "data_dic = pd.read_csv(folder + 'biz_dictionary.csv')\n",
    "data_dic.set_index('label', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dic Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_type = {}\n",
    "dic_type['int'] = 'Numeric'\n",
    "dic_type['tinyint'] = 'Numeric'\n",
    "dic_type['numeric'] = 'Numeric'\n",
    "dic_type['varchar'] = 'String'\n",
    "dic_type['date'] = 'Date'\n",
    "dic_type['smallint'] = 'Numeric'\n",
    "dic_type['numeric(5, 2)'] = 'Numeric'\n",
    "dic_type['DECIMAL(20,4)'] = 'Numeric'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate folder and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['file1', 'file2']\n",
    "folder = 'folder'\n",
    "years = [i.split('.')[0].split('_')[-1] for i in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'zipped_file': \n",
    "    {\n",
    "        'name': '', \n",
    "        'vendor': '',\n",
    "        'count': '',\n",
    "        'file_names': [],\n",
    "        'content': '',\n",
    "        'how': '',\n",
    "        'issues': '',\n",
    "        'invalid_years': [],\n",
    "        'purpose': ''\n",
    "    },\n",
    "    'individual_files': {},\n",
    "    'across_files': \n",
    "    {\n",
    "        'total_matches':'',\n",
    "        'total_returns':'',\n",
    "        \"additional_notes\":''\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize non-calculate section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input count if non matches are not returned\n",
    "input_count = 49841\n",
    "\n",
    "#zipped file section\n",
    "if min(years) == max(years):\n",
    "    zip_name = \"_\".join(files[0].split('_')[:-1] + [min(years)]) + '.zip'\n",
    "else:\n",
    "    zip_name = \"_\".join(files[0].split('_')[:-1] + [min(years)] + [max(years)]) + '.zip'\n",
    "zip_vendor = files[0].split('_')[0]\n",
    "zip_count = len(files)\n",
    "file_names = files\n",
    "\n",
    "#get from client manager\n",
    "content = ''\n",
    "purpose = ''\n",
    "\n",
    "invalid_years = []\n",
    "data['zipped_file']['name'] = zip_name\n",
    "data['zipped_file']['vendor'] = zip_vendor\n",
    "data['zipped_file']['count'] = zip_count\n",
    "data['zipped_file']['file_names'] = file_names\n",
    "data['zipped_file']['content'] = content\n",
    "data['zipped_file']['purpose'] = purpose\n",
    "data['zipped_file']['invalid_years'] = invalid_years\n",
    "\n",
    "#accross file section\n",
    "\n",
    "across_returns = '-1'\n",
    "across_notes = ''\n",
    "\n",
    "data['across_files']['total_returns'] = across_returns\n",
    "data['across_files']['additional_notes'] = across_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Each File's Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_match = []\n",
    "for file in files:\n",
    "    d=pd.read_csv(folder+file)\n",
    "    new_dic={}\n",
    "    new_dic['column_count']=d.shape[1]\n",
    "    new_dic['row_count']=d.shape[0]\n",
    "    \n",
    "    #columns\n",
    "    new_dic['columns']={}\n",
    "    for column in d.columns:\n",
    "        new_dic['columns'][column]={}\n",
    "        \n",
    "        try:\n",
    "            new_dic['columns'][column][\"description\"]=data_dic.loc[column.split('.')[-1],'label']+' (description:'\\\n",
    "                                                    +data_dic.loc[column.split('.')[-1],'description'] +')'\n",
    "            new_dic['columns'][column]['datatype']=dic_type[data_dic.loc[column.split('.')[-1],'datatype']]\n",
    "        except:\n",
    "            new_dic['columns'][column][\"description\"] = ''\n",
    "            new_dic['columns'][column]['datatype'] = find_type(d,column)\n",
    "            \n",
    "        #need to add int to make type consistent\n",
    "        new_dic['columns'][column]['missing']=int(max(input_count, d.count()['id'])-d.count()[column])\n",
    "        new_dic['columns'][column]['manipulated']=False\n",
    "        new_dic['columns'][column]['raw']=True\n",
    "        new_dic['columns'][column]['additional']=''\n",
    "        \n",
    "    new_dic['hit_rate']=max(d.count()[1:])/max(input_count, d.count()['id'])\n",
    "    new_dic['invalid_columns']=[]\n",
    "    new_dic['issues']=''\n",
    "    data['individual_files'][file]=new_dic\n",
    "    \n",
    "    #accross file matches\n",
    "    cur_match.extend(list(d['id']))\n",
    "data['across_files']['total_matches'] = len(set(cur_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attributes = []\n",
    "for column in sample.columns:\n",
    "    if sample[column].count()>5000 and len(sample[column].value_counts())<100 and len(sample[column].value_counts())>1:\n",
    "        categorical_attributes.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    for column in categorical_attributes:\n",
    "        data['individual_files'][file]['columns'][column]['datatype'] = 'Categorical Variables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store(data)\n",
    "data = load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
