{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(folder, file):\n",
    "    with open(folder + file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "    \n",
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            if len(x) == 0:\n",
    "                out[name[:-1]] = ''\n",
    "            else:\n",
    "                i = 0\n",
    "                for a in x:\n",
    "                    flatten(a, name + str(i) + '_')\n",
    "                    i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def remove_duplicate_columns(data):\n",
    "    duplicate_columns = []\n",
    "    for column in data.columns:\n",
    "        for other_column in data.columns:\n",
    "            if column+'_0' == other_column[:len(column)+2]:\n",
    "                duplicate_columns.append(column)\n",
    "                break  \n",
    "    data.drop(columns = duplicate_columns, inplace = True)\n",
    "\n",
    "def create_csv(folder, li, category):\n",
    "    if len(li) == 0:\n",
    "        return\n",
    "    first_file = True\n",
    "    \n",
    "    for file in li:\n",
    "        data = load(folder, file)\n",
    "        dic = flatten_json(data)\n",
    "        dic['file'] = file.split('.')[0]\n",
    "        cur_data = pd.DataFrame.from_dict(dic, orient='index').T\n",
    "        if first_file:\n",
    "            df = cur_data\n",
    "        else:\n",
    "            df = pd.concat([df, cur_data])\n",
    "        first_file = False\n",
    "        \n",
    "    #drop empty columns\n",
    "    remove_duplicate_columns(df)\n",
    "    \n",
    "    #move file to the first column\n",
    "    df_file = df.file\n",
    "    df = df.drop('file',axis=1)\n",
    "    df.insert(0,'file',df_file)\n",
    "    \n",
    "    #save data to the same folder\n",
    "    df.to_csv(folder + str(len(li)) + '_' + category + '.csv', index = False)\n",
    "    \n",
    "def create_summary_csv(folder):\n",
    "    file_list = os.listdir(folder)\n",
    "    news_list = [i for i in file_list if 'news' in i]\n",
    "    blog_list = [i for i in file_list if 'blogs' in i]\n",
    "    create_csv(folder, news_list, 'news')\n",
    "    create_csv(folder, blog_list, 'blogs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder = '/Users/claraliu/Downloads/json_to_change/'\n",
    "create_summary_csv(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_0000004.json\n",
      "news_0000012.json\n",
      "news_0000028.json\n",
      "news_0000008.json\n",
      "news_0000032.json\n",
      "news_0000024.json\n",
      "news_0000025.json\n",
      "news_0000033.json\n",
      "news_0000029.json\n",
      "news_0000044.json\n",
      "news_0000013.json\n",
      "news_0000005.json\n",
      "news_0000018.json\n",
      "news_0000022.json\n",
      "news_0000014.json\n",
      "news_0000043.json\n",
      "news_0000038.json\n",
      "news_0000039.json\n",
      "news_0000042.json\n",
      "news_0000015.json\n",
      "news_0000003.json\n",
      "news_0000023.json\n",
      "news_0000035.json\n",
      "news_0000020.json\n",
      "news_0000036.json\n",
      "news_0000041.json\n",
      "news_0000016.json\n",
      "news_0000017.json\n",
      "news_0000040.json\n",
      "news_0000037.json\n",
      "news_0000021.json\n",
      "news_0000010.json\n",
      "news_0000006.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_0000030.json\n",
      "news_0000031.json\n",
      "news_0000007.json\n",
      "news_0000011.json\n"
     ]
    }
   ],
   "source": [
    "first_file = 1\n",
    "for file in news_list:\n",
    "    data = load(folder, file)\n",
    "    dic = flatten_json(data)\n",
    "    dic['file'] = file.split('.')[0]\n",
    "    print(file)\n",
    "    cur_data = pd.DataFrame.from_dict(dic, orient='index').T\n",
    "    if first_file == 1:\n",
    "        df = cur_data\n",
    "    else:\n",
    "        df = pd.concat([df, cur_data])\n",
    "    first_file = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entities_locations\n",
      "entities_organizations\n",
      "entities_persons\n",
      "external_links\n"
     ]
    }
   ],
   "source": [
    "duplicate_columns = []\n",
    "for column in df.columns:\n",
    "    for other_column in df.columns:\n",
    "        if column+'_0' == other_column[:len(column)+2]:\n",
    "            duplicate_columns.append(column)\n",
    "            print(column)\n",
    "            break      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
